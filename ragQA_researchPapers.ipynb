{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOsmSEEwvqbkfuUNNzc1FZJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adi1bioinfo/NLP-Projects/blob/master/ragQA_researchPapers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Q&A tool using LangChain"
      ],
      "metadata": {
        "id": "5AN4h3tEmH9N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing all required libraries"
      ],
      "metadata": {
        "id": "f932lwXzftPj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCjJW8jjgY9E"
      },
      "outputs": [],
      "source": [
        "# The main framework for building the application\n",
        "!pip install langchain\n",
        "\n",
        "# Specific LangChain packages for community integrations and Google's models\n",
        "!pip install langchain_community langchain_core langchain_google_genai\n",
        "\n",
        "# The library for turning text into numerical vectors (embeddings)\n",
        "!pip install sentence-transformers\n",
        "\n",
        "# The library for our local vector database (a super-fast search index)\n",
        "!pip install faiss-cpu\n",
        "\n",
        "# The library for loading text from PDF files\n",
        "!pip install pypdf\n",
        "\n",
        "!pip install -U langchain-huggingface"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API key setting and gemini model selction"
      ],
      "metadata": {
        "id": "V2eF7BL3gBJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# securely loading secret key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# Initializes the connection to the Google Gemini model\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\")\n",
        "# llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
        "\n",
        "# Now, let's test it by asking a simple question\n",
        "try:\n",
        "    response = llm.invoke(\"Can you explain what a transformer model is in one sentence?\")\n",
        "    print(\"Connection successful!\")\n",
        "    print(response.content)\n",
        "except Exception as e:\n",
        "    print(\"An error occurred. Please check your API key and permissions.\")\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnoshGo40zS4",
        "outputId": "e67d3fe5-640d-4988-bc68-3a41cd312ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connection successful!\n",
            "A transformer is a neural network architecture that excels at understanding context and relationships in sequential data, like text, by using a self-attention mechanism to weigh the importance of all input elements relative to each other.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uploading all research paper in a folder then using them"
      ],
      "metadata": {
        "id": "Z8CTSsM4gOiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "\n",
        "folder_path = \"research_papers/\"\n",
        "\n",
        "# Create the loader, pointing it to our folder and load them\n",
        "loader = PyPDFDirectoryLoader(folder_path)\n",
        "all_docs = loader.load()\n",
        "\n",
        "print(f\"Successfully loaded {len(all_docs)} pages from your documents.\")\n",
        "\n",
        "# You can also inspect the metadata of the first page to see the source file\n",
        "print(\"\\n--- Metadata of the second page ---\\n\")\n",
        "print(all_docs[1].metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fd0cQiZ6Mf_",
        "outputId": "3e5313c5-6a46-4cca-cec1-2be9c5a254bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded 323 pages from your documents.\n",
            "\n",
            "--- Metadata of the second page ---\n",
            "\n",
            "{'producer': 'GPL Ghostscript 9.15', 'creator': 'Arbortext Advanced Print Publisher 9.0.215/W Unicode', 'creationdate': '2021-07-22T15:50:14+01:00', 'moddate': '2021-07-22T15:50:14+01:00', 'title': '16269654912414 1..29', 'source': 'research_papers/A signal capture and proofreading.pdf', 'total_pages': 29, 'page': 1, 'page_label': '2'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting documents into Chunks"
      ],
      "metadata": {
        "id": "2NtfpErygZVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# This splitter will try to break text up into chunks of 2000 characters\n",
        "# with a 200-character overlap.\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=2000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "\n",
        "# Split the loaded documents into chunks\n",
        "chunks = text_splitter.split_documents(all_docs)\n",
        "\n",
        "# Check the results\n",
        "print(f\"Split the {len(all_docs)} pages into {len(chunks)} chunks.\\n\")\n",
        "\n",
        "# You can also see what a single chunk looks like\n",
        "print(\"\\n--- Example Chunk ---\\n\")\n",
        "print(chunks[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FbxexEyffdC",
        "outputId": "53046983-e698-4266-8548-3e49722ff156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split the 323 pages into 851 chunks.\n",
            "\n",
            "\n",
            "--- Example Chunk ---\n",
            "\n",
            "*For correspondence:\n",
            "francis.barr@bioch.ox.ac.uk (FAB);\n",
            "simon.newstead@bioch.ox.ac.uk\n",
            "(SN)\n",
            "†These authors contributed\n",
            "equally to this work\n",
            "Competing interests:The\n",
            "authors declare that no\n",
            "competing interests exist.\n",
            "Funding:\n",
            "See page 26\n",
            "Received: 14 March 2021\n",
            "Accepted: 16 June 2021\n",
            "Published: 17 June 2021\n",
            "Reviewing editor: Adam\n",
            "Linstedt, Carnegie Mellon\n",
            "University, United States\n",
            "Copyright Gerondopoulos et\n",
            "al. This article is distributed under\n",
            "the terms of the\n",
            "Creative\n",
            "Commons Attribution License,\n",
            "which permits unrestricted use\n",
            "and redistribution provided that\n",
            "the original author and source are\n",
            "credited.\n",
            "A signal capture and proofreading\n",
            "mechanism for the KDEL-receptor\n",
            "explains selectivity and dynamic range in\n",
            "ER retrieval\n",
            "Andreas Gerondopoulos†, Philipp Bra¨ uer†, Tomoaki Sobajima, Zhiyi Wu,\n",
            "Joanne L Parker, Philip C Biggin, Francis A Barr*, Simon Newstead*\n",
            "Department of Biochemistry, University of Oxford, Oxford, United Kingdom\n",
            "Abstract ER proteins of widely differing abundance are retrieved from the Golgi by the KDEL-\n",
            "receptor. Abundant ER proteins tend to have KDEL rather than HDEL signals, whereas ADEL and\n",
            "DDEL are not used in most organisms. Here, we explore the mechanism of selective retrieval signal\n",
            "capture by the KDEL-receptor and how HDEL binds with 10-fold higher affinity than KDEL. Our\n",
            "results show the carboxyl-terminus of the retrieval signal moves along a ladder of arginine residues\n",
            "as it enters the binding pocket of the receptor. Gatekeeper residues D50 and E117 at the entrance\n",
            "of this pocket exclude ADEL and DDEL sequences. D50N/E117Q mutation of human KDEL-\n",
            "receptors changes the selectivity to ADEL and DDEL. However, further analysis of HDEL, KDEL,\n",
            "and RDEL-bound receptor structures shows that affinity differences are explained by interactions\n",
            "between the variable/C0 4 H/K/R position of the signal and W120, rather than D50 or E117.\n",
            "Together, these findings explain KDEL-receptor selectivity, and how signal variants increase\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Vector database"
      ],
      "metadata": {
        "id": "hmzeQoJlhsJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding Model: Hugging Face (all-MiniLM-L6-v2) model which is specifically rained to read a piece of text and convert its meaning into a list of numbers called a vector.\n",
        "\n",
        "Vector Store (FAISS): Using a library called FAISS (Facebook AI Similarity Search) to create my database. This is an efficient tool for storing thousands of vectors and finding the ones most similar to a new query vector almost instantly."
      ],
      "metadata": {
        "id": "fTZLljAuiJIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Take each chunk from our list, then Runs it through the embedding model to get a vector and then stores all the vectors in the FAISS index\n",
        "db = FAISS.from_documents(chunks, embeddings)"
      ],
      "metadata": {
        "id": "DDBiszdxhvwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Q&A chain"
      ],
      "metadata": {
        "id": "7PJgY8yElb2G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will take user's question, Retrieves relevant document chunks from the FAISS database then inserts those chunks and the question into a prompt and then sends the complete prompt to the LLM to generate a final answer."
      ],
      "metadata": {
        "id": "whjzmT7elumO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import create_retrieval_chain\n",
        "\n",
        "# LLM\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\")\n",
        "\n",
        "# Creating a retriever from our vector store, this is responsible for fetching relevant documents.\n",
        "retriever = db.as_retriever()\n",
        "\n",
        "# Creating a prompt template, this tells the LLM how to use the retrieved documents and the user's question.\n",
        "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "Answer the following question based only on the provided context.\n",
        "Provide a detailed and well-structured answer. If the answer is not in the context, say that you don't know.\n",
        "\n",
        "<context>\n",
        "{context}\n",
        "</context>\n",
        "\n",
        "Question: {input}\n",
        "\"\"\")\n",
        "\n",
        "# Creating the document chain, which is responsible for taking the retrieved documents and formatting them into the prompt.\n",
        "document_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Creating the main retrieval chain, this is the final chain that orchestrates the entire process.\n",
        "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
      ],
      "metadata": {
        "id": "4wgg9lwMlWlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ask a question!\n",
        "question = \"What were the primary conclusions of the study on CRISPR-Cas9?\"\n",
        "response = retrieval_chain.invoke({\"input\": question})\n",
        "\n",
        "# Print the question and final answer\n",
        "print(\"--- Question ---\")\n",
        "print(question)\n",
        "print(\"--- Answer ---\")\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgs0Kto-ooXH",
        "outputId": "cd5ac32b-68b9-4f00-b34d-fc6003021309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Question ---\n",
            "What were the primary conclusions of the study on CRISPR-Cas9?\n",
            "--- Answer ---\n",
            "Based on the context provided, I don't know what the primary conclusions of the study on CRISPR-Cas9 were. The provided text does not mention CRISPR-Cas9. The context discusses qPCR methodology, the phylogenetics and functions of PQ-loop proteins, and lists various laboratory reagents and equipment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ask a question!\n",
        "question = \"What were the important residues in KDEL receptor and what are their functioning\"\n",
        "response = retrieval_chain.invoke({\"input\": question})\n",
        "\n",
        "# Print the question and final answer\n",
        "print(\"--- Question ---\")\n",
        "print(question)\n",
        "print(\"--- Answer ---\")\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suXjy-BypiCc",
        "outputId": "c5340119-81e5-43c0-88d6-dae18a7191b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Question ---\n",
            "What were the important residues in KDEL receptor and what are their functioning\n",
            "--- Answer ---\n",
            "Based on the provided context, the following are the important residues in the KDEL receptor and their functions:\n",
            "\n",
            "**1. Residues Involved in Ligand/Signal Binding and Selectivity:**\n",
            "\n",
            "*   **D112:** This residue interacts with a threonine at position -7 of the KDEL motif on the natural ligand.\n",
            "*   **I56 and L116:** These are two of four amino acids in the receptor that interact with an isoleucine at position -6 of the ligand.\n",
            "*   **E117:** In KDELR3, the loop containing this residue is altered compared to KDELR1 and KDELR2. This residue is located close to other residues on the receptor's surface that are important for signal selectivity.\n",
            "*   **H12:** This residue is involved in creating a salt-hydrogen bond (SHB) that is destabilized in the ER, leading to the release of the KDEL peptide.\n",
            "\n",
            "**2. Residues Involved in Vesicle Trafficking (COP-I and COP-II Binding):**\n",
            "\n",
            "*   **K201, K204, and K206:** This C-terminal lysine-rich group is exposed on the cytoplasmic side when the receptor binds to the KDEL peptide. This group functions as a **COP-I binding site**.\n",
            "*   **D87, E143, and E145:** These residues are part of a negatively charged acidic motif on the cytosolic surface that is exposed when the receptor is in its unbound (apo) state. This motif is suggested to be a potential **ER-exit motif** and/or a specific **binding site for COP-II**.\n",
            "\n",
            "**3. Residue Involved in Ligand Release:**\n",
            "\n",
            "*   **H12:** In the higher pH environment of the ER, H12 becomes deprotonated. This destabilizes a salt-hydrogen bond (SHB) and consequently induces the release of the KDEL-peptide from the receptor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ask a question!\n",
        "question = \"SHB is made between which residues? and how His12 is playing important role?\"\n",
        "response = retrieval_chain.invoke({\"input\": question})\n",
        "\n",
        "# Print the question and final answer\n",
        "print(\"--- Question ---\")\n",
        "print(question)\n",
        "print(\"--- Answer ---\")\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1obGlXvqWmj",
        "outputId": "cb8fb430-1ed5-4f31-d398-fee771079202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Question ---\n",
            "SHB is made between which residues? and how His12 is playing important role?\n",
            "--- Answer ---\n",
            "Based on the provided context, here is a detailed and well-structured answer:\n",
            "\n",
            "### Residues Involved in the Short Hydrogen Bond (SHB)\n",
            "\n",
            "The short hydrogen bond (SHB) is formed between the following two residues:\n",
            "*   **Y158**, located on the transmembrane helix 6 (TM6).\n",
            "*   **E127**, located on the transmembrane helix 5 (TM5).\n",
            "\n",
            "### The Important Role of His12 (H12)\n",
            "\n",
            "His12 (H12), a conserved histidine residue on transmembrane helix 1 (TM1), plays a crucial and multi-faceted role in the KDEL protein retrieval mechanism. Its importance is derived from its location and its chemical properties.\n",
            "\n",
            "1.  **pH Sensor:** Due to its ability to be protonated, H12 is considered the **pH sensor** for the entire process. The pH difference between the Golgi (acidic) and the ER (near-neutral) is the key trigger for binding and release, and H12 is the residue that detects this change.\n",
            "\n",
            "2.  **Enabling SHB Formation:** The formation of the SHB between Y158 and E127 is directly dependent on the state of H12.\n",
            "    *   In the acidic environment of the Golgi, when the KDEL receptor is bound to a KDEL protein, **H12 becomes protonated**.\n",
            "    *   This protonation of H12 is described as **essential** for the formation of the SHB. The context also notes that H12 is adjacent to the residues Y158 and E127 that form the bond.\n",
            "\n",
            "3.  **Blocking the KDEL-Peptide:** The ultimate function of the SHB, which H12's protonation facilitates, is to secure the ligand within the receptor. The SHB **blocks the C-terminal portion (position -1) of the KDEL-peptide**, trapping it within the receptor. This is the final step in a \"handover pattern\" where the peptide is passed between other residues before being locked in place by the SHB.\n"
          ]
        }
      ]
    }
  ]
}